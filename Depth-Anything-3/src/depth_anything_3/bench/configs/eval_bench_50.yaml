# DepthAnything3 Benchmark Evaluation Configuration
# 
# This config can be loaded and overridden via command line.
# Example: python -m depth_anything_3.bench.evaluator --model /path/to/model --work_dir /path/to/workspace
#
# See depth_anything_3.cfg for config utility functions.

stage_2:
  model: VGGTMVRM
  target: RAE.src.stage2.models.DDTMVRM_pos_multi.DiTwDDTHead
  params:
    input_size: 16
    patch_size: 1
    vggt_patch_size: 14
    in_channels: 1024
    # hidden_size: [1536, 2880]
    # hidden_size: [1280, 2880]
    hidden_size: [1152, 2048]
    depth: [28, 2]
    num_heads: [16, 16]
    mlp_ratio: 4.0
    use_qknorm: true
    use_swiglu: true
    use_rmsnorm: true
    wo_shift: false
    use_pos_embed: false
  extract_layer: 0
  # ckpt: /mnt/dataset1/jaeeun/MVR_vggt/RAE/ckpts/train_hypersim_tartanair_nearcam__val_eth3d__nearrandom/VGGTMVRM__ddp2__val30_seed__g3__kernel100__view4__fp32__ep10__bs-8__lr-2e-04__ema0.9995/checkpoints/step-0021000.pt
  # ckpt: /mnt/dataset1/jaeeun/MVR_vggt/RAE/ckpts/train_hypersim_tartanair_nearcam__val_eth3d__nearrandom/VGGTMVRM__ddp2__deg_first__val30_seed__change_learning_rate_schedule__g0__kernel100__view4__fp32__ep10__bs-8__lr-2e-04__ema0.9995/checkpoints/step-0021000.pt
  # ckpt: /mnt/dataset1/jaeeun/MVR_vggt/RAE/ckpts/train_hypersim_tartanair_nearcam__val_eth3d__nearrandom/VGGTMVRM__test__deg_first__val30_seed__ckpt2000__g0__kernel200__view4__fp32__ep10__bs-4__lr-2e-04__ema0.9995/checkpoints/step-0028000.pt
  ckpt: /media/data1/MV_Restoration/JIHYE2_CKPT/kernel50_14000.pt

transport:
  params:
    path_type: 'Linear'
    prediction: 'velocity'
    loss_weight: null
    time_dist_type: 'logit-normal_0_1'

sampler:
  mode: ODE
  params:
    sampling_method: 'euler'
    num_steps: 50
    atol: 1.0e-6
    rtol: 1.0e-3
    reverse: false

misc:
  # latent_size: [1041, 1024]
  num_classes: 0
  # time_dist_shift_dim: 1065984 # 1041*1024
  time_dist_shift_base: 4096
  
# ==============================================================================
# Model Configuration
# ==============================================================================
model:
  # Path to model checkpoint or HuggingFace model ID
  path: facebook/VGGT-1B
  # path: depth-anything/DA3-GIANT-1.1

# ==============================================================================
# Workspace Configuration
# ==============================================================================
workspace:
  # Working directory for outputs (model results, metrics, etc.)
  work_dir: /mnt/dataset1/MV_Restoration/ECCV26_RESULTS/VGGT/wo_mvrm/clean

# ==============================================================================
# Dataset Configuration
# ==============================================================================
dataset:
  clean_root_path: /mnt/dataset1/MV_Restoration/da3_benchmark_dataset/clean
  deg_root_path: /mnt/dataset1/MV_Restoration/da3_benchmark_dataset/cam_blur_300

# ==============================================================================
# Evaluation Configuration
# ==============================================================================
eval:
  # Datasets to evaluate
  # Options: dtu, dtu64, eth3d, 7scenes (sevenscenes), scannetpp, hiroom
  datasets:
    - eth3d
    - 7scenes
    - scannetpp
    - hiroom
    - dtu
    - dtu64

  # Evaluation modes
  # Options: pose, recon_unposed, recon_posed, view_syn
  modes:
    - pose
    - recon_unposed
    - recon_posed

  # Reference view selection strategy for inference
  # Options: first, saddle_balanced, auto, mid
  ref_view_strategy: "first"

  # Specific scenes to evaluate (null = all scenes)
  # Example: [courtyard, relief] for eth3d
  scenes: null

  # Maximum number of frames per scene (for sampling)
  # If a scene has more frames, randomly sample to this limit.
  # Set to -1 to disable sampling.
  max_frames: 50

  # Only run evaluation (skip inference)
  eval_only: false

  # Only print saved metrics (skip inference and evaluation)
  print_only: false

# ==============================================================================
# Inference Configuration
# ==============================================================================
inference:
  # Number of parallel workers for TSDF fusion
  num_fusion_workers: 4

  # Enable debug mode with verbose output
  debug: true

# ==============================================================================
# Preset Configurations
# ==============================================================================
# These can be activated via command line: --preset full_eval

presets:
  # Full evaluation on all 6 datasets
  full_eval:
    datasets: [eth3d, 7scenes, scannetpp, hiroom, dtu, dtu64]
    modes: [pose, recon_unposed, recon_posed]

  # Pose-only evaluation
  pose_only:
    datasets: [eth3d, 7scenes, scannetpp, hiroom, dtu64]
    modes: [pose]

  # Reconstruction-only evaluation (5 datasets, excluding dtu64)
  recon_only:
    datasets: [eth3d, 7scenes, scannetpp, hiroom, dtu]
    modes: [recon_unposed, recon_posed]

  # Quick test (single scene per dataset)
  quick_test:
    datasets: [eth3d]
    modes: [pose, recon_unposed]
    scenes: [courtyard]

